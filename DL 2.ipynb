{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7df8ff8d-26d8-47d9-b1ec-10a6b5daee89",
   "metadata": {},
   "source": [
    "1. Describe the structure of an artificial neuron. How is it similar to a biological neuron? What\n",
    "are its main components?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebff08d1-c665-4801-93b7-051db716ec4e",
   "metadata": {},
   "source": [
    "An artificial neuron is a connection point in an artifical neural network.Artificial neural network networks, like the \n",
    "human body's biological neural network, have a layered architecture and each network node (connection point) has the \n",
    "capability to process input and forward output to other nodes in the network.\n",
    "\n",
    "Artificial neural network process information in a faster pace. Biological neurons are slow in processing information.\n",
    "Incapable to perform complex pattern recognition.The enormous size and complexity of the connections provided brain a \n",
    "capability of the performing complex  tasks.\n",
    "\n",
    "Input.The inputs are simply the measures of our features\n",
    "\n",
    "Weight.Weights represent scalar multiplications\n",
    "\n",
    "Transfer Function.The transfer function is different from the other components in that it takes multiple inputs\n",
    "\n",
    "Bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ed24f-59b3-41fe-85b4-77bebe966028",
   "metadata": {},
   "source": [
    "2. What are the different types of activation functions popularly used? Explain each of them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64809f7-3342-4636-92f6-274b40e18bc5",
   "metadata": {},
   "source": [
    "Binary step Function:\n",
    "    \n",
    "    Binary step functions depends on a threshold value that decides wheather a neuron should be activated or not.\n",
    "\n",
    "Linear Activation Function:\n",
    "    \n",
    "    The linear activation function, also known as \"no activation,\" or \"indentity function\" (multiplied x1.0), is where the\n",
    "    activation is proporation to the input.\n",
    "    \n",
    "Non Linear Activation Function:\n",
    "    \n",
    "    The linear activation function shown above is simply a linear regression model.\n",
    "\n",
    "Because of its limited power, this does not allow the model to create complex mapping between the network's input and outputs.\n",
    "\n",
    "Tanh and sigmoid cause huge vanishing gradient problems.Hence, they should not be used.\n",
    "Start with ReLU in your network. Activation layer is added after the weight layer (something like CNN, RNN, LSTM or linear\n",
    "dense layer) as discussed above in the article. If you think the model has stopped learning, then you can replace it with a\n",
    "LeakyReLU to avoid the Dying ReLU problem. However, the Leaky ReLU will increase the computation time a little bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdd3b0f-368a-4377-b4d8-95ecee61274d",
   "metadata": {},
   "source": [
    "4. Explain the learning process of an ANN. Explain, with example, the challenge in assigning\n",
    "synaptic weights for the interconnection between neurons? How can this challenge be\n",
    "addressed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdcf6c2-a7dc-4ff6-ac66-7d40973fbc0a",
   "metadata": {},
   "source": [
    "Architectures of Neural Network:\n",
    "    \n",
    "    ANN is a computational system consisting of many interconnected units called artificial neurons.The connection  between artificial neurons can transmit a signal from one neuron to another. So, there are multiple possibilities for connecting the  neurons based on which the architecture we are going to adopt for a specific solution.Some permutations and combinations are as follows:\n",
    "        \n",
    "        There may be just two layers of neuron in the network - the input and output layer.\n",
    "        There can be one or more intermediate \"hidden\" layers of a neuron.\n",
    "        The neurons may be connected with the neurons in the next layer\n",
    "    \n",
    "    ANN can learn and make intelligent decision on their own for new data but it is deeper than machine learning.\n",
    "    ANN is applied in finance domain, machine learning and artificial intelligence.\n",
    "    Learning such as Kohenen, radial bias, feed-forward neural network fall under ANN.\n",
    "    Some examples of ANN are face recognition, image recognition,etc.\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7d7b0-ea1e-4363-95d5-ff7e4c2d1cd5",
   "metadata": {},
   "source": [
    "5. Explain, in details, the backpropagation algorithm. What are the limitations of this\n",
    "algorithm?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a88adc-b465-4409-a97b-f87fb0c8addc",
   "metadata": {},
   "source": [
    "The backpropagation algorithum works by computing the gradient of the loss function with respect to each weight by the chain \n",
    "rule, computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculation of \n",
    "intermediate terms in the chain rule.\n",
    "\n",
    "The biggest disadvantage of Backpropagation are:\n",
    "    \n",
    "    Backpropagation could be rather sensitive to noisy data and irregularity. The performance of backpropagation relies very hearvily on the training data. Backpropagation needs a very large amount of time for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4208824a-8922-4a12-90e5-18693d60fd9f",
   "metadata": {},
   "source": [
    "6. Describe, in details, the process of adjusting the interconnection weights in a multi-layer\n",
    "neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e11366-2d27-4671-8997-c31665165b82",
   "metadata": {},
   "source": [
    "Weight of Interconnected Nodes:\n",
    "    \n",
    "    Deciding the value of weights attached with each interconnection between each neuron so that a specific learing problem can be solved correctly is quite a difficult problem by itself.Take an example to understand the problem. Take the example of multi-layered Feed-Forward network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab5d4fd-6be5-42cc-bae4-f1c36ff2bbc7",
   "metadata": {},
   "source": [
    "7. What are the steps in the backpropagation algorithm? Why a multi-layer neural network is\n",
    "required?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1bcfbc-680f-4710-b9d7-b7cfe78c1794",
   "metadata": {},
   "source": [
    "Backpropagation Algorithum:\n",
    "    \n",
    "    Step1:\n",
    "           Inputs X, arrive through the preconnected path.\n",
    "            \n",
    "    Step2:\n",
    "           Calculate the output of each neuron from the input layer to the hidden layer to the output layer.\n",
    "    Step3:\n",
    "           Calculate the output of each neuron from the input layer to the hidden layer to the output layer.\n",
    "    Step4:\n",
    "           Calculate the error in the outputs\n",
    "            \n",
    "            Backpropagation Error=Actual Output - Desired Output\n",
    "    \n",
    "    Step5:  \n",
    "            From the output layer, go back to the hidden layer to adjust the weights to reduce the error.\n",
    "    Step6:\n",
    "           Repeat the process until the desired output is achieved.\n",
    "\n",
    "A multilayer naural network with appropriate weights has been shown to be able to approximate any input-output function\n",
    "making it an attractive tool for modeling and forecasting.\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac25a162-e7ac-4ec1-863e-0f1a5dc9e0da",
   "metadata": {},
   "source": [
    "8. Write short notes on:\n",
    "\n",
    "    1. Artificial neuron\n",
    "    2. Multi-layer perceptron\n",
    "    3. Deep learning\n",
    "    4. Learning rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96944559-2730-4e28-9514-aa2df763f3b0",
   "metadata": {},
   "source": [
    "1..\n",
    "\n",
    "    An artificial neuron is a mathematical function conceived as a model of biological neurons, a neural network. Artificial neurons are elementary units in an artificaial neural network.[1] The artificial neuron recieves one or more inputs (representing excitatory postsynaptic potentials and inhibitory postsynaptic potentials at neural dendrites) and sums them to produce an output (or activation, representing a neuron's action potential which is transmitted along its axon). An artificial neuron is a mathametical function conceived as a model of biological neurons, a neural network. Artificial neurons are elementary units in an artificial neural network.[1]The artificial neuron receives one or more inputs (representing excitatory postsynaptic potentials and inhabitory postsynaptic potentials at neural dendrites) and sums them to produce an output (or activation, representing a neuron's action potential which is transmitted along its axons)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe71ee-3140-4d25-b149-68e69c1d4642",
   "metadata": {},
   "source": [
    "2..\n",
    "\n",
    "    Multi-layer perception is also known as MPL. It is fully connected dense layers, which transform any input dimension to the desired dimension. A multi-layer perception is a neural network that has multiple layers. To create a neural network we combine neurons together so that the output of  some neurons are inputs of other neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790482fc-f609-40ab-8a81-058f59687755",
   "metadata": {},
   "source": [
    "3...\n",
    "\n",
    "    Deep learning is a subset of machine learning, which is essentially a neural network with three or more layers.These neural networks attempt to simulate the behavior of the human brain-albeit far from matching its ability-allowing it to \"learn\" from large amounts of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1803a725-27f6-486f-95ce-c715d81c7d76",
   "metadata": {},
   "source": [
    "4..\n",
    "\n",
    "    Learning rate is a hyper-parameter that controls the weights of our neural network with respect to the loss gradient.It defines how quickly the neural network updates the concepts it has learned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc715efa-64dc-44dc-b6ac-dc3814e2e8ce",
   "metadata": {},
   "source": [
    "2. Write the difference between:\n",
    "\n",
    "    1. Activation function vs threshold function\n",
    "    2. Step function vs sigmoid function\n",
    "    3. Single layer vs multi-layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8be568-a3fb-482f-b7f2-f3a0f0fcd565",
   "metadata": {},
   "source": [
    "A.\n",
    "    \n",
    "    A threshold value determines whether a neuron should be activated or not activated in a binary step actiavation function. The actiavation function compares the input value to a threshold value. It the input value is greater then the threshold value, the neuron is activated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7fe132-6098-44d3-87a1-d6ff2fc2ae70",
   "metadata": {},
   "source": [
    "B.\n",
    "\n",
    "     The (Heaviside) step function is typically only usefull within single-layer perceptrons, an early type of neural networks that can be used for classification in cases where the input data is lineraly separable.However, Multi-layer neural networks or multi-layer perceptrons are of more interest because they are general function approximators and they are able to distinguish data that is not linearly seperable. Multi-layer perceptrons are trained using backropagation.A requirement for backpropagation is a differentiable activation function. That's because backpropagation uses gradient descent on this function to update the network weights. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc8902a-2232-4772-b54f-48aec9eb689d",
   "metadata": {},
   "source": [
    "C.\n",
    "\n",
    "    A Multi Layer Perceptron(MLP) contains one or more hidden layers (apart from one input and one output layer). While a single layer perceptron can only learn linear functions, a multi layer perceptron can also learn non -linear functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41464780-ed90-40bf-943d-5291c332fd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
